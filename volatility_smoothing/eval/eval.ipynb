{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "storedir = None  # Set this to persist evaluation results/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if storedir is not None:\n",
    "    checkpoint_storedir = f\"{storedir}/checkpoints\"\n",
    "    Path(checkpoint_storedir).mkdir(exist_ok=True)\n",
    "\n",
    "    data_storedir = f\"{storedir}/data\"\n",
    "    Path(data_storedir).mkdir(exist_ok=True)\n",
    "else:\n",
    "    checkpoint_storedir = None\n",
    "    data_storedir = None\n",
    "    \n",
    "try:\n",
    "    job_id = os.environ['PBS_JOBID'].split('.pbs')[0]\n",
    "except KeyError:\n",
    "    job_id = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "logger = logging.getLogger('job')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Importing third-party packages ...')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from volatility_smoothing.utils.chunk import chunked\n",
    "from volatility_smoothing.utils.train.loss import Loss\n",
    "from volatility_smoothing.utils.options_data import SPXOptionsDataset\n",
    "from volatility_smoothing.utils.train.dataset import GNOOptionsDataset\n",
    "from volatility_smoothing.utils.chunk import chunked\n",
    "from volatility_smoothing.utils.train import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Defining device (torch.cuda.is_available()={torch.cuda.is_available()})\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logger.info(f'Running using device `{device}`')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\n",
    "    formatted_result = str(result.stdout).replace('\\\\n', '\\n').replace('\\\\t', '\\t')##\n",
    "\n",
    "    logger.info(formatted_result)\n",
    "    logger.info(f'Device count: {torch.cuda.device_count()}')\n",
    "    logger.info(f'Visible devices count: {os.environ[\"CUDA_VISIBLE_DEVICES\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPDS_CACHE_DIR'] = os.path.expanduser('~/.cache/opds')  # directory where to place the processed files\n",
    "os.environ['OPDS_WRDS_DATA_DIR'] = os.path.abspath(\"../data/wrds/spx\")  # <- .csv file from WRDS should be place inside this directory\n",
    "dataset = SPXOptionsDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from volatility_smoothing.utils.options_data import OptionsDataset\n",
    "\n",
    "\n",
    "def split_dataset(dataset: OptionsDataset):\n",
    "    \"\"\"Splits dataset in <2021 training portion, and 2020 test portion (sub-split into months)\"\"\"\n",
    "    train_indices = []\n",
    "    val_indices = [[] for _ in range(12)]\n",
    "\n",
    "    for idx, file_path in enumerate(dataset.file_paths):\n",
    "        date_str = str(file_path).split('_')[-1].replace('.pt', '')\n",
    "        date = datetime.strptime(date_str, '%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "        if date.year < 2021:\n",
    "            train_indices.append(idx)\n",
    "        elif date.year == 2021:\n",
    "            month = date.month - 1\n",
    "            val_indices[month].append(idx)\n",
    "\n",
    "    train_dataset, dev_dataset = random_split(Subset(GNOOptionsDataset(dataset), train_indices), [0.982, 0.018])\n",
    "    test_datasets = [Subset(GNOOptionsDataset(dataset), indices) for indices in val_indices]\n",
    "\n",
    "    return train_dataset, dev_dataset, test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, dev_dataset, test_datasets = split_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "weight_decay = 1e-5\n",
    "\n",
    "checkpoint_path = \"../train/store/9448705/checkpoints/checkpoint_final.pt\"\n",
    "model, _ = misc.load_checkpoint(checkpoint_path, device=device)\n",
    "model.to(device);\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation/Finetuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "\n",
    "epochs = 10  # Finetune epochs, set to 0 to skip and just evaluate\n",
    "batch_size = 32  # Finetune batch size, will be augmented by same amount of training data\n",
    "\n",
    "# mesh sizes on which to evaluate arbitrage metrics\n",
    "step_r = 0.02\n",
    "step_z = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = Loss()\n",
    "dev_loss = Loss(step_r=step_r, step_z=step_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(model, optimizer, train_dataset: GNOOptionsDataset, finetune_dataset: GNOOptionsDataset, dev_dataset: GNOOptionsDataset, **kwargs):\n",
    "\n",
    "    logger = logging.getLogger('job')\n",
    "\n",
    "    kwargs = kwargs.copy()\n",
    "    num_workers = kwargs.pop('num_workers', 0)\n",
    "    epochs = kwargs.pop('epochs', 10)\n",
    "    batch_size = kwargs.pop('batch_size', 64)\n",
    "    dev_loss = kwargs.pop('dev_loss', Loss())\n",
    "    callback = kwargs.pop('callback', lambda sample_loss: sample_loss.backward())\n",
    "    checkpoint_storedir = kwargs.pop('checkpoint_storedir', None)\n",
    "\n",
    "    loss = Loss(**kwargs)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=1, collate_fn=loss.collate_fn, shuffle=True, num_workers=num_workers, pin_memory=False)\n",
    "    finetune_dataloader = DataLoader(finetune_dataset, batch_size=1, collate_fn=train_loss.collate_fn, shuffle=True, num_workers=num_workers, pin_memory=False)\n",
    "\n",
    "    logger.info(50 * \"=\")\n",
    "    logger.info(\"Training start:\")\n",
    "    logger.info(f\"Epochs: {epochs}\")\n",
    "    logger.info(loss)\n",
    "    logger.info(50 * \"=\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        train_iterator = iter(train_dataloader)\n",
    "        finetune_iterator = iter(finetune_dataloader)\n",
    "\n",
    "        for batch_idx in (iterations := tqdm(chunked(list(range(len(finetune_dataloader))), batch_size))):\n",
    "            batch = ([next(train_iterator) for _ in batch_idx]\n",
    "                     + [next(finetune_iterator) for _ in batch_idx])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            batch_loss, loss_infos = loss.compute_batch_loss(model, batch, callback, device)\n",
    "            loss_str = loss.format_loss_str(loss_infos)                                        \n",
    "            iterations.set_description(loss_str)\n",
    "            optimizer.step()\n",
    "        \n",
    "            if (iterations.n % 10 == 0) and (storedir is not None):\n",
    "                logger.info(f\"Epoch {epoch}; {iterations.n}/{len(iterations)} -- {loss_str}\")\n",
    "\n",
    "\n",
    "        # Dev loss\n",
    "        df_val, df_rel, df_fit = dev_loss.evaluate(model, dev_dataset, device=device, num_workers=num_workers)\n",
    "        logger.info(f\"Epoch {epoch} Dev: {df_val.describe()}\")\n",
    "\n",
    "        # Checkpointing\n",
    "        if checkpoint_storedir is not None and not batch_loss.isnan():\n",
    "            checkpoint = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{checkpoint_storedir}/{job_id}_checkpoint_{epoch}.pt\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "logger.info(50 * \"=\")\n",
    "logger.info(f\"Evaluation start (Retraining epochs: {epochs}).\")\n",
    "logger.info(50 * \"=\")\n",
    "\n",
    "finetune_dataset = Subset(train_dataset, [])\n",
    "try:\n",
    "    for k, test_dataset in enumerate(test_datasets):\n",
    "\n",
    "        df_val, df_rel, df_fit = dev_loss.evaluate(model, test_dataset, device=device, num_workers=num_workers, storedir=storedir, logger=logger)\n",
    "\n",
    "        finetune_dataset = ConcatDataset([finetune_dataset, test_dataset])\n",
    "        finetune(model, optimizer, train_dataset, finetune_dataset, dev_dataset,\n",
    "                 dev_loss=dev_loss, epochs=epochs, batch_size=batch_size, num_workers=num_workers, checkpoint_storedir=checkpoint_storedir)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logging.info(\"Training aborted\")\n",
    "else:\n",
    "    logging.info(\"Training complete\")\n",
    "finally:\n",
    "    if checkpoint_storedir is not None:\n",
    "        checkpoint = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(model, f\"{checkpoint_storedir}/checkpoint_final.pt\")\n",
    "    model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:operator-deep-smoothing-for-implied-volatility]",
   "language": "python",
   "name": "conda-env-operator-deep-smoothing-for-implied-volatility-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
